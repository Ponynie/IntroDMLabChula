{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop unnescessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plts\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('/Users/ponynie/Developer/Python_Code/IntroDMLabChula/Final_Project/children anemia.csv')\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "data.drop(['Anemia level.1', 'Hemoglobin level adjusted for altitude and smoking (g/dl - 1 decimal)', 'When child put to breast', 'Current marital status'], axis=1, inplace=True)\n",
    "\n",
    "data = data[data['Had fever in last two weeks'].isin(['Yes', 'No'])]\n",
    "data = data[data['Taking iron pills, sprinkles or syrup'].isin(['Yes', 'No'])]\n",
    "\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps categorical to codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Age in 5-year groups', 'Type of place of residence', 'Highest educational level', 'Wealth index combined', 'Have mosquito bed net for sleeping (from household questionnaire)', 'Smokes cigarettes', 'Currently residing with husband/partner', 'Had fever in last two weeks', 'Taking iron pills, sprinkles or syrup']\n",
    "numerical_columns = ['Births in last five years', 'Age of respondent at 1st birth', 'Hemoglobin level adjusted for altitude (g/dl - 1 decimal)']\n",
    "label_columns = ['Anemia level']\n",
    "\n",
    "for category in categorical_columns:\n",
    "    data[category] = data[category].astype('category')\n",
    "data['Anemia level'] = data['Anemia level'].astype('category')\n",
    "\n",
    "for categorical in categorical_columns:\n",
    "    print(data[categorical].cat.categories, categorical)\n",
    "print(data['Anemia level'].cat.categories, \"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in numerical_columns:\n",
    "    data[col] = (data[col] - data[col].min())/ (data[col].max() - data[col].min())\n",
    "\n",
    "data[numerical_columns].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    data[col] = (data[col].cat.codes.values - data[col].cat.codes.values.min()) / (data[col].cat.codes.values.max() - data[col].cat.codes.values.min())\n",
    "    \n",
    "data[categorical_columns].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create nparray of categorical matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_np = [data[i] for i in categorical_columns]\n",
    "categorical_data = np.stack(categorical_np, 1)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Categorical Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = torch.tensor(categorical_data, dtype=torch.float64)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create nparray of numerical matrix and convert to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = np.stack([data[i].values for i in numerical_columns], 1)\n",
    "numerical_data = torch.tensor(numerical_data, dtype=torch.float)\n",
    "numerical_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create label's Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.tensor(data['Anemia level'].cat.codes.values).flatten()\n",
    "outputs[200:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check correctness of dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data.shape, numerical_data.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data to train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_records = data.shape[0]\n",
    "test_records = int(total_records * .2) # 20% of the data for testing\n",
    "train_records = total_records - test_records # 80% of the data for training\n",
    "\n",
    "categorical_train_data = categorical_data[:train_records]\n",
    "categorical_test_data = categorical_data[train_records:]\n",
    "numerical_train_data = numerical_data[:train_records]\n",
    "numerical_test_data = numerical_data[train_records:]\n",
    "train_outputs = outputs[:train_records]\n",
    "test_outputs = outputs[train_records:]\n",
    "\n",
    "print(categorical_train_data.shape, categorical_test_data.shape)\n",
    "print(numerical_train_data.shape, numerical_test_data.shape)\n",
    "print(train_outputs.shape, test_outputs.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, numerical_features_size, categorical_features_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        all_features_size = numerical_features_size + categorical_features_size\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(all_features_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),  \n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),  \n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "        )\n",
    "        # Initialize weights\n",
    "        for layer in self.linear_relu_stack:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.cat((categorical_train_data, numerical_train_data), dim=1).requires_grad_(True)\n",
    "test_data = torch.cat((categorical_test_data, numerical_test_data), dim=1).requires_grad_(True)\n",
    "print(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.float()\n",
    "test_data = test_data.float()\n",
    "train_outputs = train_outputs.long()\n",
    "test_outputs = test_outputs.long()\n",
    "print(train_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features_size = numerical_data.shape[1]\n",
    "categorical_features_size = categorical_data.shape[1]\n",
    "hidden_size = 6\n",
    "num_epochs = 20\n",
    "learning_rate = 0.1\n",
    "output_size = 4\n",
    "batch_size = 100\n",
    "\n",
    "model = NeuralNetwork(numerical_features_size, categorical_features_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "train_data = train_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "train_outputs = train_outputs.to(device)\n",
    "test_outputs = test_outputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_data, train_outputs)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 10 == 9:  # Print every 100 batches\n",
    "            print(f\"Epoch {epoch + 1}, Batch {batch_idx + 1}, Loss: {running_loss / 100:.4f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {loss.item()}\")\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    outputs = model(test_data)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print(predicted)\n",
    "    print(test_outputs)\n",
    "    total += test_outputs.size(0)\n",
    "    correct += (predicted == test_outputs).sum().item()\n",
    "    print(correct)\n",
    "    print(total)\n",
    "\n",
    "print(f\"Accuracy of the model on the test data: {(100 * correct / total)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
