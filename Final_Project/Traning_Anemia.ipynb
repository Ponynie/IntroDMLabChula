{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.init as init\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('/Users/ponynie/Developer/Python_Code/IntroDMLabChula/Final_Project/children anemia.csv')\n",
    "data.drop('Anemia level.1', axis=1, inplace=True)\n",
    "data.dropna(subset=['Anemia level', 'Had fever in last two weeks','Taking iron pills, sprinkles or syrup'],inplace=True)\n",
    "data['Currently residing with husband/partner'] = data['Currently residing with husband/partner'].fillna(data['Currently residing with husband/partner'].median)\n",
    "data['Hemoglobin level adjusted for altitude and smoking (g/dl - 1 decimal)'] = data['Hemoglobin level adjusted for altitude and smoking (g/dl - 1 decimal)'].fillna(data['Hemoglobin level adjusted for altitude and smoking (g/dl - 1 decimal)'].mean)\n",
    "data['Age in 5-year groups'] = data['Age in 5-year groups'].apply(lambda x: sum(map(int,x.split('-')))/2)\n",
    "data.drop(columns=['When child put to breast', 'Hemoglobin level adjusted for altitude (g/dl - 1 decimal)'],inplace=True)\n",
    "data = data[data['Currently residing with husband/partner'].isin(['Living with her', 'Staying elsewhere'])]\n",
    "data = data[data['Had fever in last two weeks'].isin(['No', 'Yes'])]\n",
    "data = data[data['Taking iron pills, sprinkles or syrup'].isin(['No', 'Yes'])]\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Current marital status', 'Type of place of residence', 'Highest educational level', 'Wealth index combined', 'Have mosquito bed net for sleeping (from household questionnaire)', 'Smokes cigarettes', 'Currently residing with husband/partner', 'Had fever in last two weeks', 'Taking iron pills, sprinkles or syrup']\n",
    "numerical_columns = ['Age in 5-year groups', 'Births in last five years', 'Age of respondent at 1st birth', 'Hemoglobin level adjusted for altitude and smoking (g/dl - 1 decimal)']\n",
    "label_columns = 'Anemia level'\n",
    "\n",
    "for category in categorical_columns:\n",
    "    data[category] = data[category].astype('category')\n",
    "data['Anemia level'] = data['Anemia level'].astype('category')\n",
    "\n",
    "for categorical in categorical_columns:\n",
    "    print(data[categorical].cat.categories, categorical)\n",
    "print(data['Anemia level'].cat.categories, \"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_np = [data[i].cat.codes.values for i in categorical_columns]\n",
    "categorical_data = np.stack(categorical_np, 1)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = torch.tensor(categorical_data, dtype=torch.int64)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = np.stack([data[i].values for i in numerical_columns], 1)\n",
    "numerical_data = torch.tensor(numerical_data, dtype=torch.float)\n",
    "numerical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.tensor(data['Anemia level'].cat.codes.values).flatten()\n",
    "outputs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data.shape, numerical_data.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_sizes = [len(data[column].cat.categories) for column in categorical_columns]\n",
    "categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_column_sizes]\n",
    "print(categorical_embedding_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_records = data.shape[0]\n",
    "test_records = int(total_records * .2) # 20% of the data for testing\n",
    "train_records = total_records - test_records # 80% of the data for training\n",
    "\n",
    "categorical_train_data = categorical_data[:train_records]\n",
    "categorical_test_data = categorical_data[train_records:]\n",
    "numerical_train_data = numerical_data[:train_records]\n",
    "numerical_test_data = numerical_data[train_records:]\n",
    "train_label = outputs[:train_records]\n",
    "test_label = outputs[train_records:]\n",
    "\n",
    "print(categorical_train_data.shape, categorical_test_data.shape)\n",
    "print(numerical_train_data.shape, numerical_test_data.shape)\n",
    "print(train_label.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, num_numerical_cols, output_size, layers, p=0.4):\n",
    "        super().__init__()\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "        self.batch_norm_num = nn.BatchNorm1d(num_numerical_cols)\n",
    "\n",
    "        all_layers = []\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols + num_numerical_cols\n",
    "\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, x_categorical, x_numerical):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.embedding_dropout(x)\n",
    "\n",
    "        x_numerical = self.batch_norm_num(x_numerical)\n",
    "        x = torch.cat([x, x_numerical], 1)\n",
    "        x = self.layers(x)\n",
    "        return x #(batch_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [200,100,50]\n",
    "model = Model(categorical_embedding_sizes, numerical_data.shape[1], 4, hidden_layers, p=0.4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    print (\"MPS device found.\")\n",
    "else:\n",
    "    print(\"MPS device not found.\")\n",
    "\n",
    "mps_device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model.to(mps_device)\n",
    "categorical_train_data = categorical_train_data.to(mps_device)\n",
    "numerical_train_data = numerical_train_data.to(mps_device)\n",
    "categorical_test_data = categorical_test_data.to(mps_device)\n",
    "numerical_test_data = numerical_test_data.to(mps_device)\n",
    "train_label = train_label.to(mps_device)\n",
    "test_label = test_label.to(mps_device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    pred = model(categorical_train_data, numerical_train_data)\n",
    "    single_loss = loss_function(pred, train_label)\n",
    "    aggregated_losses.append(single_loss)\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "\n",
    "aggregated_losses_on_cpu = [tensor.detach().cpu() for tensor in aggregated_losses]\n",
    "plt.plot(range(epochs), aggregated_losses_on_cpu)\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    eval = model(categorical_test_data, numerical_test_data)\n",
    "    loss = loss_function(eval, test_label)\n",
    "print(f'Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval[:5])\n",
    "eval = np.argmax(eval.detach().cpu(), axis=1)\n",
    "print(eval[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label.detach().cpu()\n",
    "print(confusion_matrix(test_label,eval))\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "print(classification_report(test_label,eval))\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "print(f\"accuracy: {accuracy_score(test_label, eval)*100} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
