{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRO DMDW Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.init as init\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('/Users/ponynie/Developer/Python_Code/IntroDMLabChula/Final_Project/Hotel Reservations.csv')\n",
    "data.drop(['Booking_ID'], axis=1, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separeate categorical columns, numerical columns and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['type_of_meal_plan', \n",
    "                       'room_type_reserved', \n",
    "                       'arrival_year', \n",
    "                       'market_segment_type', \n",
    "                       'required_car_parking_space']\n",
    "numerical_columns = ['no_of_adults', \n",
    "                     'no_of_children', \n",
    "                     'no_of_weekend_nights', \n",
    "                     'no_of_week_nights', \n",
    "                     'lead_time', \n",
    "                     'arrival_month', \n",
    "                     'arrival_date', \n",
    "                     'repeated_guest', \n",
    "                     'no_of_previous_cancellations', \n",
    "                     'no_of_previous_bookings_not_canceled', \n",
    "                     'avg_price_per_room', \n",
    "                     'no_of_special_requests']\n",
    "label_column = 'booking_status'\n",
    "\n",
    "for category in categorical_columns:\n",
    "    data[category] = data[category].astype('category')\n",
    "data[label_column] = data[label_column].astype('category')\n",
    "\n",
    "for categorical in categorical_columns:\n",
    "    print(data[categorical].cat.categories, categorical)\n",
    "print(data[label_column].cat.categories, \"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical columns to number and convert to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_np = [data[i].cat.codes.values for i in categorical_columns]\n",
    "categorical_data = np.stack(categorical_np, 1)\n",
    "categorical_data = torch.tensor(categorical_data, dtype=torch.int64)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert numerical columns to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = np.stack([data[i].values for i in numerical_columns], 1)\n",
    "numerical_data = torch.tensor(numerical_data, dtype=torch.float)\n",
    "numerical_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert label to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.tensor(data[label_column].cat.codes.values).flatten()\n",
    "outputs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check correctness of dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data.shape, numerical_data.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding categorical columns for better perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_sizes = [len(data[column].cat.categories) for column in categorical_columns]\n",
    "categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_column_sizes]\n",
    "print(categorical_embedding_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate tran test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_records = data.shape[0]\n",
    "test_records = int(total_records * .2) # 20% of the data for testing\n",
    "train_records = total_records - test_records # 80% of the data for training\n",
    "\n",
    "categorical_train_data = categorical_data[:train_records]\n",
    "categorical_test_data = categorical_data[train_records:]\n",
    "numerical_train_data = numerical_data[:train_records]\n",
    "numerical_test_data = numerical_data[train_records:]\n",
    "train_label = outputs[:train_records]\n",
    "test_label = outputs[train_records:]\n",
    "\n",
    "print(categorical_train_data.shape, categorical_test_data.shape)\n",
    "print(numerical_train_data.shape, numerical_test_data.shape)\n",
    "print(train_label.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model and network topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, num_numerical_cols, output_size, layers, p=0.4):\n",
    "        super().__init__()\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "        self.batch_norm_num = nn.BatchNorm1d(num_numerical_cols)\n",
    "\n",
    "        all_layers = []\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols + num_numerical_cols\n",
    "\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, x_categorical, x_numerical):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.embedding_dropout(x)\n",
    "\n",
    "        x_numerical = self.batch_norm_num(x_numerical)\n",
    "        x = torch.cat([x, x_numerical], 1)\n",
    "        x = self.layers(x)\n",
    "        return x #(batch_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust hidden layers and instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [200,100,50]\n",
    "class_count = int(data[label_column].cat.codes.nunique())\n",
    "\n",
    "model = Model(categorical_embedding_sizes, numerical_data.shape[1], class_count, hidden_layers, p=0.4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move all Tensor to MPS backend for GPU training acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    print (\"MPS device found.\")\n",
    "else:\n",
    "    print(\"MPS device not found.\")\n",
    "\n",
    "mps_device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model.to(mps_device)\n",
    "categorical_train_data = categorical_train_data.to(mps_device)\n",
    "numerical_train_data = numerical_train_data.to(mps_device)\n",
    "categorical_test_data = categorical_test_data.to(mps_device)\n",
    "numerical_test_data = numerical_test_data.to(mps_device)\n",
    "train_label = train_label.to(mps_device)\n",
    "test_label = test_label.to(mps_device)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    pred = model(categorical_train_data, numerical_train_data)\n",
    "    single_loss = loss_function(pred, train_label)\n",
    "    aggregated_losses.append(single_loss)\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "\n",
    "aggregated_losses_on_cpu = [tensor.detach().cpu() for tensor in aggregated_losses]\n",
    "plt.plot(range(epochs), aggregated_losses_on_cpu)\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    eval = model(categorical_test_data, numerical_test_data)\n",
    "    loss = loss_function(eval, test_label)\n",
    "print(f'Loss: {loss:.8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval[:5])\n",
    "eval = np.argmax(eval.detach().cpu(), axis=1)\n",
    "print(eval[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label.detach().cpu()\n",
    "\n",
    "print(confusion_matrix(test_label, eval))\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "print(classification_report(test_label, eval))\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "print(f\"accuracy: {accuracy_score(test_label, eval)*100} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
